<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>protHMM</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">protHMM</h1>



<div id="introduction" class="section level2">
<h2>1: Introduction</h2>
<p>The goal of protHMM is to help integrate profile hidden markov model
(HMM) representations of proteins into the machine learning and
bioinformatics workflow. protHMM ports a number of features from use in
Position Specific Scoring Matrices (PSSMs) to HMMs, along with
implementing features used with HMMs specifically, which to our
knowledge has not been done before. The adoption of HMM representations
of proteins derived from <a href="https://doi.org/10.1038/nmeth.1818">HHblits</a> and <a href="http://hmmer.org">HMMer</a> also presents an opportunity for
innovation; it has been shown that HMMs can benefit from better multiple
sequence alignment than PSSMs and thus get better results than
corresponding HMMs using similar feature extraction techniques <span class="citation">(Lyons et al. 2015)</span>. protHMM implements 20
different feature extraction techniques to provide a comprehensive list
of feature sets for use in bioinformatics tasks ranging from protein
fold classification to protein-protein interaction.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(protHMM)</span></code></pre></div>
</div>
<div id="autocorrelation-hmm_mb-hmm_ma-hmm_ga" class="section level2">
<h2>2: Autocorrelation: hmm_MB, hmm_MA, hmm_GA</h2>
<p>protHMM implements normalized Moreau-Broto, Moran and Geary
autocorrelation descriptors, each of which measure the correlation
between two amino acid residues separated by a lag value, (lg) along the
sequence. Each of these feature vectors return a vector of <span class="math inline">\(20 \times lg\)</span>. <span class="citation">Liang, Liu, and Zhang (2015)</span> provide a
mathematical representation for each of these features, having used them
to predict protein structural class:</p>
<div id="moreau-broto" class="section level4">
<h4>Moreau-Broto</h4>
<p><span class="math inline">\({N_{lg}^j = \frac{1} {L-lg} \sum_{i = 1}
^ {L-lg} H_{i, j} \times H_{i+lg, j}, \space (j = 1,2..20, 0 &lt; d &lt;
L)}\)</span></p>
<p>In which <span class="math inline">\({N_{lg}^j}\)</span> is the
Moreau-Broto correlation factor for column <span class="math inline">\(j\)</span>, <span class="math inline">\(lg\)</span> is the lag value, <span class="math inline">\(L\)</span> is the length of the protein sequence
and <span class="math inline">\(H\)</span> represents the HMM
matrix.</p>
</div>
<div id="moran" class="section level4">
<h4>Moran</h4>
<p><span class="math inline">\({N_{lg}^j = \frac{\frac{1} {L-lg} \sum_{i
= 1} ^ {L-lg} (H_{i, j} - \bar{H_j}) \times (H_{i+lg, j} -
\bar{H_j})}{\frac {1} {L} \sum_{i = 1} {L} (H_{i, j} - \bar{H_j})^2},
\space (j = 1,2..20, 0 &lt; d &lt; L)}\)</span></p>
<p>In which <span class="math inline">\({N_{lg}^j}\)</span> is the Moran
correlation factor for column <span class="math inline">\(j\)</span>,
<span class="math inline">\(lg\)</span> is the lag value, <span class="math inline">\(L\)</span> is the length of the protein sequence,
<span class="math inline">\(\bar{H_j}\)</span> represents the average of
column <span class="math inline">\(j\)</span> in matrix <span class="math inline">\(H\)</span> and <span class="math inline">\(H\)</span> represents the HMM matrix.</p>
</div>
<div id="geary" class="section level4">
<h4>Geary</h4>
<p><span class="math inline">\({N_{lg}^j = \frac{\frac{1} {2(L-lg)}
\sum_{i = 1} ^ {L-lg} (H_{i, j} - H_{i+d, j})^2}{\frac {1} {L-1} \sum_{i
= 1} {L} (H_{i, j} - \bar{H_j})^2}, \space (j = 1,2..20, 0 &lt; d &lt;
L)}\)</span></p>
<p>In which <span class="math inline">\({N_{lg}^j}\)</span> is the Geary
correlation factor for column <span class="math inline">\(j\)</span>,
<span class="math inline">\(lg\)</span> is the lag value, <span class="math inline">\(L\)</span> is the length of the protein sequence
and <span class="math inline">\(H\)</span> represents the HMM
matrix.</p>
</div>
<div id="examples" class="section level4">
<h4>Examples</h4>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(protHMM)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="do">## basic example code</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>h_MB<span class="ot">&lt;-</span> <span class="fu">hmm_MB</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>h_MA<span class="ot">&lt;-</span> <span class="fu">hmm_MA</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>h_GA<span class="ot">&lt;-</span> <span class="fu">hmm_GA</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(h_MB, <span class="dv">20</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 0.0027399767 0.0028318487 0.0030151714 0.0027021756 0.0029396909</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [6] 0.0028727712 0.0030186241 0.0028945067 0.0029009803 0.0006026105</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [11] 0.0003812977 0.0004823361 0.0003340628 0.0005073259 0.0003092559</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [16] 0.0002997833 0.0010281865 0.0004959552 0.0023601628 0.0021576905</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(h_MA, <span class="dv">20</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] -0.10731521 -0.08432884  0.03573254 -0.15878664  0.03660993 -0.02897298</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7]  0.05583864 -0.02260616 -0.01659614 -0.00317749 -0.02603402 -0.01744969</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13] -0.03281501 -0.01579394 -0.03647018 -0.03876510  0.03093880 -0.02196930</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [19]  0.31531271  0.17506839</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(h_GA, <span class="dv">20</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 1.0866849 1.0541761 0.9300136 1.1177010 0.9217161 0.9864679 0.9015713</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [8] 0.9811766 0.9780934 1.0025380 1.0347499 1.0360329 1.0615057 1.0546791</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [15] 1.0855622 1.0984717 1.0403336 1.1041239 0.6773725 0.8157369</span></span></code></pre></div>
</div>
</div>
<div id="covariance-hmm_ac-hmm_cc" class="section level2">
<h2>3: Covariance: hmm_AC, hmm_CC</h2>
<p>protHMM implements two covariance-based features, autocovariance (AC)
and cross covariance (CC). These features calculate the covariance
between two residues separated by a lag value lg along the sequence. AC
calculates this for positions in the same column, and CC for positions
that are not in the same column of the HMM. It should also be noted that
for these features, the HMM matrix is not converted to probabilities,
unlike other features. Both features were used for protein fold
recognition.</p>
<div id="autocovariance" class="section level4">
<h4>Autocovariance</h4>
<p><span class="citation">Dong, Zhou, and Guan (2009)</span> provide a
mathematical representation of autocovariance:</p>
<p><span class="math inline">\(AC(j, lg) = \sum_{i = 1}^{L-lg}
\frac{(H_{i, j} - \bar{H_j}) \times (H_{i+lg, j} - \bar{H_j})}{L-lg},
\space j = 1,2..20\)</span></p>
<p>In which <span class="math inline">\(AC(j,\space lg)\)</span> is the
autocovariance factor for column <span class="math inline">\(j\)</span>,
<span class="math inline">\(lg\)</span> is the lag value, <span class="math inline">\(L\)</span> is the length of the protein sequence,
<span class="math inline">\(\bar{H_j}\)</span> represents the average of
column <span class="math inline">\(j\)</span> in matrix <span class="math inline">\(H\)</span> and <span class="math inline">\(H\)</span> represents the HMM matrix.</p>
</div>
<div id="cross-covariance" class="section level4">
<h4>Cross covariance</h4>
<p><span class="citation">Dong, Zhou, and Guan (2009)</span> also
provide a mathematical representation of cross covariance:</p>
<p><span class="math inline">\(AC(j_1, j_2, lg) = \sum_{i = 1}^{L-lg}
\frac{(H_{i, j_1} - \bar{H_{j_1}}) \times (H_{i+lg, j_2} -
\bar{H_{j_2})}}{L-lg}, \space j_1,j_2 = 1, 2, 3...20, \space j_1 \neq
j_2\)</span></p>
<p>In which <span class="math inline">\(AC(j_1,\space j_2,\space
lg)\)</span> is the cross correlation factor for columns <span class="math inline">\(j_1, \space j_2\)</span>, <span class="math inline">\(lg\)</span> is the lag value, <span class="math inline">\(L\)</span> is the length of the protein sequence,
<span class="math inline">\(\bar{H_{j_i}}\)</span> represents the
average of column <span class="math inline">\(j_i\)</span> in matrix
<span class="math inline">\(H\)</span> and <span class="math inline">\(H\)</span> represents the HMM matrix.</p>
</div>
<div id="examples-1" class="section level4">
<h4>Examples</h4>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(protHMM)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="do">## basic example code</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>h_AC<span class="ot">&lt;-</span> <span class="fu">hmm_ac</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>h_CC<span class="ot">&lt;-</span> <span class="fu">hmm_cc</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(h_AC, <span class="dv">20</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 2027588 2048277 2069394 2090950 8161072 8244348 8329341 8416105 3815863</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [10] 3854800 3894540 3935108 2055989 2076968 2098380 2120238 4671700 4719371</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [19] 4768024 4817691</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(h_CC, <span class="dv">20</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 432613.90 607445.71 679287.41 527806.56 446405.28 989099.80 188119.73</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [8] 479781.58 547044.82  29788.07 892089.22 946319.61 520382.72 820507.43</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [15] 297221.83 194817.35 309185.70 286636.41 873835.20 -23142.80</span></span></code></pre></div>
</div>
</div>
<div id="bigrams-and-trigrams" class="section level2">
<h2>4: Bigrams and Trigrams</h2>
<p>The bigrams and trigrams features are outlined by <span class="citation">Lyons et al. (2015)</span>, and they interpret the
likelihood of 2 (bi) or 3 (tri) amino acids occurring consecutively in
the sequence. Thus, they take shape as a 20 x 20 matrix for bigrams and
a 20 x 20 x 20 array for trigrams, which are then flattened to create
vectors of length 400 and 8000. These features were used by <span class="citation">Lyons et al. (2015)</span> for protein fold
recognition.</p>
<div id="bigrams" class="section level4">
<h4>Bigrams</h4>
<p><span class="citation">Lyons et al. (2015)</span> outlines bigrams
mathematically as <span class="math inline">\(B[i, j]\)</span>,
where:</p>
<p><span class="math inline">\({B[i, j] = \sum_{a = 1}^{L-1} H_{a,
i}H_{a+1, j}}\)</span></p>
<p>And <span class="math inline">\({H}\)</span> corresponds to the
original HMM matrix, and <span class="math inline">\({L}\)</span> is the
number of rows in <span class="math inline">\({H}\)</span>.</p>
</div>
<div id="trigrams" class="section level4">
<h4>Trigrams</h4>
<p><span class="citation">Lyons et al. (2015)</span> outlines bigrams
mathematically as <span class="math inline">\(B[i, j, k]\)</span>,
where:</p>
<p><span class="math inline">\({B[i, j, k] = \sum_{a = 1}^{L-2} H_{a,
i}H_{a+1, j}H_{a+2, k}}\)</span></p>
<p>And <span class="math inline">\({H}\)</span> corresponds to the
original HMM matrix, and <span class="math inline">\({L}\)</span> is the
number of rows in <span class="math inline">\({H}\)</span>.</p>
</div>
<div id="examples-2" class="section level4">
<h4>Examples</h4>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(protHMM)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="do">## basic example code</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>h_tri<span class="ot">&lt;-</span> <span class="fu">hmm_trigrams</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>h_bi<span class="ot">&lt;-</span> <span class="fu">hmm_bigrams</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(h_tri, <span class="dv">20</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 0.005352191 0.011975355 0.019514992 0.008968399 0.018890547 0.008317675</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7] 0.013992176 0.016166307 0.022135295 0.004365804 0.013618584 0.020090544</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13] 0.008747969 0.012091065 0.024533920 0.019144562 0.017654663 0.006009293</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [19] 0.006042909 0.011424255</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(h_bi, <span class="dv">20</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 0.27125769 0.11864240 0.22349757 0.35406729 0.17926196 0.31284113</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7] 0.15635251 0.24893749 0.31070932 0.43189681 0.08388694 0.26433238</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13] 0.39767028 0.19981994 0.24877376 0.51622764 0.38255083 0.36514895</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [19] 0.12440151 0.13735055</span></span></code></pre></div>
</div>
</div>
<div id="chmm" class="section level2">
<h2>5: CHMM</h2>
<p>The CHMM feature begins by creating a CHMM, which is created by
constructing 4 matrices, <span class="math inline">\({A, B, C,
D}\)</span> from the original HMM <span class="math inline">\({H}\)</span>. <span class="math inline">\({A}\)</span> contains the first 75 percent of the
original matrix <span class="math inline">\({H}\)</span> row-wise, <span class="math inline">\({B}\)</span> the last 75 percent, <span class="math inline">\({C}\)</span> the middle 75 percent and <span class="math inline">\({D}\)</span> the entire original matrix <span class="citation">(An et al. 2019)</span>. These are then merged to
create the new CHMM <span class="math inline">\({Z}\)</span>. From
there, the bigrams feature is calculated with a flattened 20 x 20 matrix
<span class="math inline">\({B}\)</span>, in which</p>
<p><span class="math inline">\({B[i, j] = \sum_{a = 1}^{L-1} Z_{a, i}
\times Z_{a+1, j}}\)</span></p>
<p><span class="math inline">\({H}\)</span> corresponds to the original
HMM matrix, and <span class="math inline">\({L}\)</span> is the number
of rows in <span class="math inline">\({Z}\)</span> <span class="citation">(An et al. 2019)</span>. Local Average Group, or LAG is
calculated by first splitting the CHMM into <span class="math inline">\(j\)</span> groups and then the following:</p>
<p><span class="math inline">\(LAG(k) = \frac{20}{L}\sum_{p = 1}^{N/20}
Mt[p+(i-1)\times(N/20),\space j]\)</span></p>
<p>Where <span class="math inline">\({L}\)</span> is the number of rows
in <span class="math inline">\({Z}\)</span> and <span class="math inline">\(Mt[p+(i-1)\times(N/20),\space j]\)</span>
represents the row vector of the CHMM and the <span class="math inline">\(i\)</span>th position in the <span class="math inline">\(j\)</span>th group <span class="citation">(An et
al. 2019)</span>. These features are then fused, and a vector of 800
along the the original length 400 bigrams and LAG vectors are returned.
The CHMM features were used to predict protein-protein interactions.</p>
<div id="examples-3" class="section level4">
<h4>Examples</h4>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(protHMM)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>h_fused<span class="ot">&lt;-</span> <span class="fu">chmm</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))[[<span class="dv">1</span>]]</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>h_lag<span class="ot">&lt;-</span> <span class="fu">chmm</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))[[<span class="dv">2</span>]]</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>h_bigrams<span class="ot">&lt;-</span> <span class="fu">chmm</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))[[<span class="dv">3</span>]]</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(h_fused, <span class="dv">20</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 0.050431366 0.008073699 0.025377739 0.080125307 0.037055099 0.034279129</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7] 0.022591078 0.088067417 0.056547767 0.088639559 0.020870630 0.016466719</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13] 0.114605135 0.031219286 0.040658673 0.079269757 0.066999681 0.136328812</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [19] 0.009850417 0.024292606</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(h_lag, <span class="dv">20</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 0.050431366 0.008073699 0.025377739 0.080125307 0.037055099 0.034279129</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7] 0.022591078 0.088067417 0.056547767 0.088639559 0.020870630 0.016466719</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13] 0.114605135 0.031219286 0.040658673 0.079269757 0.066999681 0.136328812</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [19] 0.009850417 0.024292606</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(h_bigrams, <span class="dv">20</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 0.6644992 0.2932670 0.5686021 0.8736529 0.4484777 0.7703030 0.3734919</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [8] 0.6135072 0.7469687 1.0671193 0.2097486 0.6524548 0.9846256 0.5010583</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [15] 0.6275425 1.2841556 0.9755920 0.8980086 0.3038199 0.3414741</span></span></code></pre></div>
</div>
</div>
<div id="distance" class="section level2">
<h2>6: Distance</h2>
<p>The distance feature calculates the cosine distance matrix between
two HMMs <span class="math inline">\({A}, \space{B}\)</span> before
dynamic time warp is applied to the distance matrix calculate the
cumulative distance between the HMMs, which acts as a measure of
similarity <span class="citation">(Lyons et al. 2016)</span>. The cosine
distance matrix <span class="math inline">\({D}\)</span> is calculated
with:</p>
<p><span class="math inline">\({D[a_i, b_j] = 1 -
\frac{a_ib_j^{T}}{a_ia_i^Tb_jb_j^T}}\)</span></p>
<p>in which <span class="math inline">\({a_i}\)</span> and <span class="math inline">\({a_i}\)</span> refer to row vectors of <span class="math inline">\({A}\)</span> and <span class="math inline">\({B}\)</span> respectively <span class="citation">(Lyons et al. 2016)</span>. This in turn means that
<span class="math inline">\(D\)</span> is of dimensions <span class="math inline">\({nrow(A), nrow(b)}\)</span>. Dynamic time warp
then calculates the cumulative distance by calculating matrix:</p>
<p><span class="math inline">\(C[i, j] = min(C[i-1, j], C[i, j-1],
C[i-1, j-1]) + D[i, j]\)</span></p>
<p>where <span class="math inline">\({C_{i,j}}\)</span> is 0 when <span class="math inline">\({i}\)</span> or <span class="math inline">\({j}\)</span> are less than 1 <span class="citation">(Lyons et al. 2016)</span>. The lower rightmost point
of the matrix <span class="math inline">\({C}\)</span> is then returned
as the cumulative distance between proteins. The distance feature was
used by <span class="citation">Lyons et al. (2016)</span> for protein
fold recognition.</p>
<div id="example" class="section level4">
<h4>Example</h4>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(protHMM)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># basic example code</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>h<span class="ot">&lt;-</span> <span class="fu">hmm_distance</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>), <span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1TEN-7&quot;</span>, </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>                                                                                      <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>h</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 99.90334</span></span></code></pre></div>
</div>
</div>
<div id="fp_hmm" class="section level2">
<h2>7: FP_HMM</h2>
<p>FP_HMM consists of two vectors, <span class="math inline">\({d,
s}\)</span>. Vector <span class="math inline">\({d}\)</span> corresponds
to the sums across the sequence for each of the 20 amino acid columns
<span class="citation">(Zahiri et al. 2013)</span>. Vector <span class="math inline">\({s}\)</span> corresponds to a flattened matrix of
<span class="math inline">\(S\)</span> where:</p>
<p><span class="math inline">\({S[i, j] = \sum_{k = 1}^{L} H[k, j]
\times \delta[k, i]}\)</span></p>
<p>in which <span class="math inline">\({\delta[k, i] = 1}\)</span> when
<span class="math inline">\({A_i = H[k, j]}\)</span> and 0 otherwise
<span class="citation">(Zahiri et al. 2013)</span>. <span class="math inline">\({A}\)</span> refers to a list of all possible
amino acids, <span class="math inline">\({i, j}\)</span> span from <span class="math inline">\({1:20}\)</span>. This feature has been used for
the prediction of protein-protein interactions.</p>
<div id="example-1" class="section level4">
<h4>Example</h4>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(protHMM)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># basic example code</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>h<span class="ot">&lt;-</span> <span class="fu">fp_hmm</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>h[[<span class="dv">1</span>]]</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 5.327650 2.495163 4.226204 6.557727 3.430360 6.392750 2.638661 5.230106</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [9] 5.887156 7.882747 1.510770 4.522352 6.408192 3.615053 4.486816 9.137523</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [17] 7.110800 7.647033 1.971206 2.521788</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(h[[<span class="dv">2</span>]], <span class="dv">20</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 0.00000000 0.06906144 0.25848195 0.61607168 0.21594299 0.21617140</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7] 0.24383966 0.22567252 0.18595546 0.51564480 0.00000000 0.15273093</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13] 0.63770076 0.00000000 0.24438102 0.21709957 0.46775998 0.89909902</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [19] 0.10940189 0.05263446</span></span></code></pre></div>
</div>
</div>
<div id="hmm_gsd" class="section level2">
<h2>8: HMM_GSD</h2>
<p>This feature was created by <span class="citation">Jin and Zhu
(2021)</span> and begins by creates a grouping matrix <span class="math inline">\(G\)</span> by assigning each position a number
<span class="math inline">\(1,2, 3\)</span> based on the value at each
position of HMM matrix <span class="math inline">\(H\)</span>; <span class="math inline">\(1\)</span> represents the low probability group,
<span class="math inline">\(2\)</span> the medium and <span class="math inline">\(3\)</span> the high probability group. The number
of total points in each group for each column is then calculated, and
the sequence is then split based upon the the positions of the 1st,
25th, 50th, 75th and 100th percentile (last) positioned points for each
of the three groups, in each of the 20 columns of the grouping matrix.
Thus for column <span class="math inline">\(j\)</span>:</p>
<p><span class="math inline">\({S(k, \space j, \space z) = \sum_{i =
1}^{(z) \times.25 \times N} |G[i,\space j] = k|}\)</span></p>
<p>where <span class="math inline">\({k}\)</span> is the group number,
<span class="math inline">\({z = 1,2,3,4}\)</span> and <span class="math inline">\({N}\)</span> corresponds to number of rows in
matrix <span class="math inline">\({G}\)</span> <span class="citation">(Jin and Zhu 2021)</span>.</p>
<div id="example-2" class="section level4">
<h4>Example</h4>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(protHMM)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># basic example code</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>h<span class="ot">&lt;-</span> <span class="fu">hmm_GSD</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>h[<span class="dv">1</span><span class="sc">:</span><span class="dv">40</span>]</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1]  1.11117557  0.83022094 -0.43407491 -1.50170251 -1.67027529  0.91450733</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7]  0.54926631  0.26831167 -0.01264296 -1.58598890  1.02688918  0.94260279</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13]  0.71783909  0.43688445 -1.61408437  1.11117557  0.32450260 -0.34978852</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [19] -0.99598417 -1.67027529  0.83022094  0.71783909  0.52117084  0.24021621</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [25] -1.38932066  0.63355270  0.63355270  0.63355270  0.63355270 -1.55789344</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [31]  1.11117557  0.46497992 -0.34978852 -1.13646149 -1.67027529  1.05498465</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [37]  0.85831640  0.52117084  0.18402528 -1.50170251</span></span></code></pre></div>
</div>
</div>
<div id="pseudo-hmm-im_psehmm-and-pse_hmm" class="section level2">
<h2>9: Pseudo HMM: IM_psehmm and pse_hmm</h2>
<p>Both of the pseudo HMM features, pse_hmm and IM_psehmm, are based off
of <span class="citation">Chou and Shen (2007)</span>’s psuedo PSSM
concept. This was engineered in order to create non-variable length
representations of proteins, while keeping sequence order information.
IM_psehmm stands for improved pseudo hmm, which is based off of <span class="citation">Ruan et al. (2020)</span>’s improvements to the <span class="citation">Chou and Shen (2007)</span>’s initial offering; <span class="citation">Ruan et al. (2020)</span>’s offering is still based on
the PSSM matrix. As such, this feature is a port for use with HMMs.</p>
<div id="pseudo_hmm" class="section level4">
<h4>pseudo_hmm</h4>
<p>Mathematically, pseudo_hmm is made of the fusion of 2 vectors. The
first is of the means across the 20 amino acid emission frequency
columns of the HMM. The second can be found in the following equation
<span class="citation">(Chou and Shen 2007)</span>:</p>
<p><span class="math inline">\(V_{j}^{i} = \frac{1}{L-i}\sum_{k =
1}^{L-i}H[k, j] \times H[k+i, j], \space j = 1,2..20, \space i &lt;
L\)</span></p>
<p><span class="math inline">\(H\)</span> represents the HMM matrix,
<span class="math inline">\(L\)</span> represents the row number of
<span class="math inline">\(H\)</span>, <span class="math inline">\(i\)</span> represents the amount of contiguous
amino acids that correlation is measured across and <span class="math inline">\(V_{j}^{i}\)</span> represents the value of the
vector for the <span class="math inline">\(j\)</span>th column and <span class="math inline">\(i\)</span>th most contiguous amino acids. This
results in a vector of <span class="math inline">\(20 + g \times
20\)</span>.</p>
</div>
<div id="im_pse_hmm" class="section level4">
<h4>IM_pse_hmm</h4>
<p>IM_pse_hmm is also the fusion of two vectors, one being the same
means vector described above. The second can be found as <span class="citation">(Ruan et al. 2020)</span>:</p>
<p><span class="math inline">\(V_{j}^{d} = \frac{1}{20-d}\sum_{k =
1}^{L}H[k, j] \times H[k, j+d], \space j = 1,2..20, \space d &lt;
20\)</span></p>
<p>Where <span class="math inline">\(H\)</span> the HMM matrix, <span class="math inline">\(L\)</span> represents the number of rows in <span class="math inline">\(H\)</span> and <span class="math inline">\(V_{j}^i\)</span> represents the value in the
feature vector for column <span class="math inline">\(j\)</span> and
columnal distance parameter <span class="math inline">\(d\)</span>. This
results in a vector of length <span class="math inline">\({20+20\times
d-d\times\frac{d+1}{2}}\)</span>.</p>
</div>
</div>
<div id="local-binary-pattern" class="section level2">
<h2>10: Local Binary Pattern</h2>
<p>This feature is based off of <span class="citation">Li et al.
(2019)</span>’s work using local binary pattern to extract features from
PSSMs to use in protein-protein interaction prediction. The local binary
pattern extraction used here can be defined as <span class="math inline">\(B = b(s(H_{m, n+1}-H_{m, n}), s(H_{m+1, n+1}-H_{m,
n}), s(H_{m+1, n}-H_{m, n})...s(H_{m-1, n+1}-H_{m, n})))\)</span>, where
<span class="math inline">\(H[m,n]\)</span> signifies the center of a
local binary pattern neighborhood (<span class="math inline">\(2&lt;m&lt;L-1,2&lt;n&lt;20, L = nrow(H)\)</span>),
<span class="math inline">\(H\)</span> refers to the HMM matrix, <span class="math inline">\(s(x) = 1\)</span> if <span class="math inline">\(x
\ge 0\)</span>, <span class="math inline">\(s(x) = 0\)</span> otherwise
and <span class="math inline">\(b\)</span> refers to a function that
converts a binary number to a decimal number. The local binary pattern
features are then put into a histogram with 256 bins, one for each
possible binary value. This is returned as a 256 length vector.</p>
<div id="example-3" class="section level4">
<h4>Example</h4>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(protHMM)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="do">## basic example code</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>h<span class="ot">&lt;-</span> <span class="fu">hmm_LBP</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1TEN-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>h[<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>]</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 166  31  16  18  35   8   4   7  12   6   3   1   7   0   2   0  19   4   5</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [20]   2</span></span></code></pre></div>
</div>
</div>
<div id="linear-predictive-coding" class="section level2">
<h2>11: Linear Predictive Coding</h2>
<p>In this feature, linear predictive coding (LPC) is used to extract a
vector <span class="math inline">\(d\)</span> of length <span class="math inline">\(g\)</span> from each of the 20 amino acid emission
frequency columns of the HMM matrix. linear predictive coding considers
that position <span class="math inline">\(H[i, j]\)</span> in the HMM
matrix can be approximated by <span class="math inline">\(\sum_{k =
1}^{g} d_{k, j}a_{i,j}\)</span>. The feature vector extracted is thus
the vector of d; this is done through the phonTools package <span class="citation">(Barreda 2015)</span>. This assumes <span class="math inline">\(g\)</span> of 14, and thus the feature vector
generated if <span class="math inline">\(14\times20 = 280\)</span>. This
feature is based off of <span class="citation">Qin et al.
(2015)</span>’s work, in which they used an LPC feature set to predict
protein structural class.</p>
<div id="example-4" class="section level4">
<h4>Example</h4>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(protHMM)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="do">## basic example code</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>h<span class="ot">&lt;-</span> <span class="fu">hmm_LPC</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1TEN-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>h[<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>]</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 1.00000000 0.74635054 0.59126153 0.36331602 0.36010191 0.30277057</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7] 0.47978532 0.41120113 0.29511047 0.28022645 0.20143373 0.24002696</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13] 0.15302503 0.04457104 1.00000000 0.71845887 0.84727202 0.92128401</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [19] 1.02748498 0.83287042</span></span></code></pre></div>
</div>
</div>
<div id="scsh" class="section level2">
<h2>12: SCSH</h2>
<p>This feature is documented by <span class="citation">Mohammadi et al.
(2022)</span> and was used for protein-protein interaction prediction.
The SCSH feature returns the k-mer composition between a protein’s
consensus sequence given by the HMM and the protein’s actual sequence,
for k = 2,3. First, all possible k-mers for all of the 20 possible amino
acids are calculated (<span class="math inline">\({20^2}\)</span> and
<span class="math inline">\({20^3}\)</span> permutations for 2 and
3-mers respectively). With those permutations, different vectors of
length 400 and 8000 are created, vectors <span class="math inline">\(v_2, \space v_3\)</span>. Each position on the
vectors corresponds to a specific k-mer, i.e <span class="math inline">\(v_2[1] = AA\)</span> and <span class="math inline">\(v_2[1] = AAA\)</span>. Then, the protein sequence
that corresponds to the HMM scores is extracted, and put into a
bipartite graph with the actual protein sequence. Each path of length 1
or 2 is found on the graph, and the corresponding vertices on the graph
are noted as possible 2 and 3-mers. For each 2 or 3-mer found from these
paths, 1 is added to the position that corresponds to that 2/3-mer in
the 2-mer and 3-mer vectors, which are the length 400 and 8000 vectors
created previously. The vectors are then returned.</p>
<div id="examples-4" class="section level4">
<h4>Examples</h4>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(protHMM)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="do">## basic example code</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>h<span class="ot">&lt;-</span> <span class="fu">hmm_SCSH</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1TEN-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="do">## 2-mers</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>h[[<span class="dv">1</span>]][<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>]</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 0 0 0 1 0 2 0 0 1 1 1 0 2 0 1 0 2 1 0 0</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="do">## 3-mers: specific indexes as most of the vector is 0</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>h[[<span class="dv">2</span>]][<span class="dv">313</span><span class="sc">:</span><span class="dv">333</span>]</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 2 0 0 0</span></span></code></pre></div>
</div>
</div>
<div id="separated-dimers" class="section level2">
<h2>13: Separated Dimers</h2>
<p>Separated Dimers refers the the probability that there will be an
amino acid dimer between amino acid residues separated by a distance of
<span class="math inline">\(l\)</span>. <span class="citation">Saini et
al. (2015)</span> conceived of this feature and applied it to protein
fold recognition; mathematically, separated dimers calculates matrix
<span class="math inline">\(F\)</span>:</p>
<p><span class="math inline">\({F[m, n] = \sum_{i = 1}^{L-l} H_{i,
m}H_{i+l, n}}\)</span></p>
<p><span class="math inline">\({H}\)</span> corresponds to the original
HMM matrix, and <span class="math inline">\(L\)</span> is the number of
rows in <span class="math inline">\(H\)</span>. Matrix <span class="math inline">\(F\)</span> is then flattened to a feature vector
of length 400, and returned.</p>
<div id="examples-5" class="section level4">
<h4>Examples</h4>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(protHMM)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="do">## basic example code</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>h<span class="ot">&lt;-</span> <span class="fu">hmm_SepDim</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>h[<span class="dv">1</span><span class="sc">:</span><span class="dv">40</span>]</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 0.28073204 0.13127205 0.22465162 0.30993504 0.17705352 0.30286268</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7] 0.13611039 0.27110569 0.26843594 0.42275865 0.08623105 0.23523189</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13] 0.28262058 0.17449219 0.23466631 0.45744566 0.38400417 0.41489217</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [19] 0.06656876 0.12644926 0.12468473 0.02787985 0.17961578 0.17639461</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [25] 0.04536077 0.33523934 0.07878719 0.08306272 0.13034049 0.14246328</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [31] 0.04005923 0.13693382 0.09324879 0.10231668 0.09851687 0.29441110</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [37] 0.16511460 0.15335638 0.03221440 0.03884258</span></span></code></pre></div>
</div>
</div>
<div id="single-average-group" class="section level2">
<h2>14: Single Average Group</h2>
<p><span class="citation">Nanni, Lumini, and Brahnam (2014)</span>
pioneer the Single Average Group feature and use it for protein
classification. This feature groups together rows that are related to
the same amino acid, using a vector <span class="math inline">\({SA(k)}\)</span>, in which <span class="math inline">\({k}\)</span> spans <span class="math inline">\({1:400}\)</span> and:</p>
<p><span class="math inline">\({SA(k) = avg_{i \space = \space 1, 2...
L}\space H[i, j] \times \delta(P(i), A(z))}\)</span></p>
<p>in which <span class="math inline">\({H}\)</span> is the HMM matrix,
<span class="math inline">\({P}\)</span> in the protein sequence, <span class="math inline">\({A}\)</span> is an ordered set of amino acids, the
variables <span class="math inline">\({j, \space z = 1, 2,
3...20}\)</span>, the variable <span class="math inline">\({k = j + 20
\times (z-1)}\)</span> when creating the vector. <span class="math inline">\({\delta()}\)</span> represents Kronecker’s
delta.</p>
<div id="example-5" class="section level4">
<h4>Example</h4>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(protHMM)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="do">## basic example code</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>h<span class="ot">&lt;-</span> <span class="fu">hmm_Single_Average</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>h[<span class="dv">1</span><span class="sc">:</span><span class="dv">40</span>]</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 5.327649515 2.495163167 4.226203618 6.557727068 3.430359915 6.392750239</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7] 2.638660734 5.230106250 5.887155542 7.882747181 1.510770387 4.522351690</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13] 6.408192096 3.615052651 4.486815933 9.137522926 7.110799532 7.647033087</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [19] 1.971206424 2.521787664 0.069061438 1.448076555 0.000000000 0.000000000</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [25] 0.040982786 0.037528025 0.034250848 0.033810905 0.000000000 0.033966298</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [31] 0.018141963 0.012174447 0.061500560 0.009964409 0.031380236 0.049529900</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [37] 0.045531222 0.055012065 0.008144264 0.011430244</span></span></code></pre></div>
</div>
</div>
<div id="smoothed-hmm" class="section level2">
<h2>15: Smoothed HMM</h2>
<p>This feature extraction technique is found in <span class="citation">Fang, Noguchi, and Yamana (2013)</span>, being used in
conjunction with another technique for ligand binding site prediction.
This feature smooths the HMM matrix <span class="math inline">\(H\)</span> by using sliding window of length <span class="math inline">\(sw\)</span> to incorporate information from up and
downstream residues into each row of the HMM matrix. Foreach HMM row
:</p>
<p><span class="math inline">\(r_i = \sum_{x \space = \space
i-\frac{sw}{2}}^{i+\frac{sw}{2}}{r_x}\)</span></p>
<p>for <span class="math inline">\({i = 1, 2, 3...L}\)</span>, where
<span class="math inline">\({L}\)</span> is the number of rows in <span class="math inline">\({H}\)</span>. For rows such as the beginning and
ending rows, zero matrices of dimensions <span class="math inline">\(sw/2, 20\)</span> are appended to <span class="math inline">\({H}\)</span>.</p>
<div id="example-6" class="section level4">
<h4>Example</h4>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(protHMM)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="do">## basic example code</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>h<span class="ot">&lt;-</span> <span class="fu">hmm_smooth</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>h[<span class="dv">1</span>,]</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 0.11776641 0.01631112 0.05565213 0.11811762 0.02074633 0.18715081</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7] 0.11375485 0.18747835 0.25055389 0.12211269 0.05342971 0.12007436</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13] 0.07683993 0.16693724 0.01869764 0.24692156 0.30136984 0.67903030</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [19] 0.04331468 0.10385260</span></span></code></pre></div>
</div>
</div>
<div id="singular-value-decomposition" class="section level2">
<h2>16: Singular Value Decomposition</h2>
<p>This feature extraction method is found in <span class="citation">Song et al. (2018)</span>, and uses singular value
decomposition to extract a feature vector from a HMM matrix. SVD
factorizes the matrix <span class="math inline">\(H\)</span> of
dimensions <span class="math inline">\({i, j}\)</span> to</p>
<p><span class="math inline">\({U[i, r] \times \Sigma[r, r] \times V[r,
j]}\)</span></p>
<p>The diagonal values of <span class="math inline">\({\Sigma}\)</span>
are known as the singular values of matrix <span class="math inline">\(H\)</span>, and are what are returned with this
function. This feature was used to predict protein-protein
interactions.</p>
<div id="example-7" class="section level4">
<h4>Example</h4>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(protHMM)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># basic example code</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>h<span class="ot">&lt;-</span> <span class="fu">hmm_svd</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>h</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 2.4328414 1.1318859 1.0331369 0.9046638 0.8595964 0.6696056 0.6425755</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [8] 0.5865227 0.5189927 0.5155567 0.4701584 0.4118091 0.3627740 0.3249188</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [15] 0.2858293 0.2615811 0.2576213 0.2251676 0.2074293 0.1242763</span></span></code></pre></div>
</div>
</div>
<div id="read" class="section level2">
<h2>17: Read</h2>
<p>This function reads in the 20 amino acid emission frequency columns
used in the feature extraction methods discussed previously, and
converts the columns into probabilities.</p>
<div id="example-8" class="section level4">
<h4>Example</h4>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(protHMM)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="do">## basic example code</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>h<span class="ot">&lt;-</span> <span class="fu">hmm_read</span>(<span class="fu">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;1DLHA2-7&quot;</span>, <span class="at">package=</span><span class="st">&quot;protHMM&quot;</span>))</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>h[<span class="dv">1</span>,]</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 0.0000000 0.0000000 0.0000000 0.3410370 0.0000000 0.0000000 0.0000000</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [8] 0.3382121 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [15] 0.0000000 0.0000000 0.0000000 0.3208565 0.0000000 0.0000000</span></span></code></pre></div>
</div>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="unnumbered">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-an-2019" class="csl-entry">
An, Ji-Yong, Yong Zhou, Yu-Jun Zhao, and Zi-Ji Yan. 2019. <span>“<span class="nocase">An Efficient Feature Extraction Technique Based on Local
Coding PSSM and Multifeatures Fusion for Predicting Protein-Protein
Interactions</span>.”</span> <em>Evolutionary Bioinformatics</em> 15
(January): 117693431987992.
</div>
<div id="ref-phonTools" class="csl-entry">
Barreda, Santiago. 2015. <em>phonTools: Functions for Phonetics in
r.</em>
</div>
<div id="ref-chou-2007" class="csl-entry">
Chou, Kuo-Chen, and Hong Shen. 2007. <span>“<span class="nocase">MemType-2L: A Web server for predicting membrane proteins
and their types by incorporating evolution information through
Pse-PSSM</span>.”</span> <em>Biochemical and Biophysical Research
Communications</em> 360 (2): 339–45. <a href="https://doi.org/10.1016/j.bbrc.2007.06.027">https://doi.org/10.1016/j.bbrc.2007.06.027</a>.
</div>
<div id="ref-dong-2009" class="csl-entry">
Dong, Qiwen, Shuigeng Zhou, and Jihong Guan. 2009. <span>“<span class="nocase">A new taxonomy-based protein fold recognition approach
based on autocross-covariance transformation</span>.”</span>
<em>Bioinformatics</em> 25 (20): 2655–62. <a href="https://doi.org/10.1093/bioinformatics/btp500">https://doi.org/10.1093/bioinformatics/btp500</a>.
</div>
<div id="ref-fang-2013" class="csl-entry">
Fang, Chun, Tamotsu Noguchi, and Hayato Yamana. 2013. <span>“<span class="nocase">SCPSSMpred: A General Sequence-based Method for
Ligand-binding Site Prediction</span>.”</span> <em>IPSJ Transactions on
Bioinformatics</em> 6 (0): 35–42. <a href="https://doi.org/10.2197/ipsjtbio.6.35">https://doi.org/10.2197/ipsjtbio.6.35</a>.
</div>
<div id="ref-jin-2021" class="csl-entry">
Jin, Danyu, and Ping Zhu. 2021. <span>“<span class="nocase">Protein
Subcellular Localization Based on Evolutionary Information and Segmented
Distribution</span>.”</span> <em>Mathematical Problems in
Engineering</em> 2021 (December): 1–14. <a href="https://doi.org/10.1155/2021/8629776">https://doi.org/10.1155/2021/8629776</a>.
</div>
<div id="ref-li-2019" class="csl-entry">
Li, Yan, Liping Li, Lei Wang, Changqing Yu, Zheng Wang, and Zhu-Hong
You. 2019. <span>“<span class="nocase">An Ensemble Classifier to Predict
Protein–Protein Interactions by Combining PSSM-based Evolutionary
Information with Local Binary Pattern Model</span>.”</span>
<em>International Journal of Molecular Sciences</em> 20 (14): 3511. <a href="https://doi.org/10.3390/ijms20143511">https://doi.org/10.3390/ijms20143511</a>.
</div>
<div id="ref-liang-2015" class="csl-entry">
Liang, Yunyun, Sanyang Liu, and Zhang. 2015. <span>“<span class="nocase">Prediction of Protein Structural Class Based on Different
Autocorrelation Descriptors of Position–Specific Scoring
Matrix</span>.”</span> <em>MATCH: Communications in Mathematical and in
Computer Chemistry</em> 73 (3): 765–84.
</div>
<div id="ref-lyons-2015" class="csl-entry">
Lyons, James, Abdollah Dehzangi, Rhys Heffernan, Yuedong Yang, Yaoqi
Zhou, Alok Sharma, and Kuldip K. Paliwal. 2015. <span>“<span class="nocase">Advancing the Accuracy of Protein Fold Recognition by
Utilizing Profiles From Hidden Markov Models</span>.”</span> <em>IEEE
Transactions on Nanobioscience</em> 14 (7): 761–72. <a href="https://doi.org/10.1109/tnb.2015.2457906">https://doi.org/10.1109/tnb.2015.2457906</a>.
</div>
<div id="ref-lyons-2016" class="csl-entry">
Lyons, James, Kuldip K. Paliwal, Abdollah Dehzangi, Rhys Heffernan,
Tatsuhiko Tsunoda, and Alok Sharma. 2016. <span>“<span class="nocase">Protein fold recognition using HMM–HMM alignment and
dynamic programming</span>.”</span> <em>Journal of Theoretical
Biology</em> 393 (March): 67–74. <a href="https://doi.org/10.1016/j.jtbi.2015.12.018">https://doi.org/10.1016/j.jtbi.2015.12.018</a>.
</div>
<div id="ref-mohammadi-2022" class="csl-entry">
Mohammadi, Alireza M., Javad Zahiri, Saber Mohammadi, Mohsen Khodarahmi,
and Seyed Shahriar Arab. 2022. <span>“<span class="nocase">PSSMCOOL: a
comprehensive R package for generating evolutionary-based descriptors of
protein sequences from PSSM profiles</span>.”</span> <em>Biology Methods
and Protocols</em> 7 (1). <a href="https://doi.org/10.1093/biomethods/bpac008">https://doi.org/10.1093/biomethods/bpac008</a>.
</div>
<div id="ref-nanni-2014" class="csl-entry">
Nanni, Loris, Alessandra Lumini, and Sheryl Brahnam. 2014. <span>“<span class="nocase">An Empirical Study of Different Approaches for Protein
Classification</span>.”</span> <em>The Scientific World Journal</em>
2014 (January): 1–17. <a href="https://doi.org/10.1155/2014/236717">https://doi.org/10.1155/2014/236717</a>.
</div>
<div id="ref-qin-2015" class="csl-entry">
Qin, Yufang, Xiaoqi Zheng, Jun Wang, Ming Chen, and Changjie Zhou. 2015.
<span>“<span class="nocase">Prediction of protein structural class based
on Linear Predictive Coding of PSI-BLAST profiles</span>.”</span>
<em>Central European Journal of Biology</em> 10 (1). <a href="https://doi.org/10.1515/biol-2015-0055">https://doi.org/10.1515/biol-2015-0055</a>.
</div>
<div id="ref-ruan-2020" class="csl-entry">
Ruan, Xiaoli, Dongming Zhou, Rencan Nie, and Yanbu Guo. 2020.
<span>“<span class="nocase">Predictions of Apoptosis Proteins by
Integrating Different Features Based on Improving
Pseudo-Position-Specific Scoring Matrix</span>.”</span> <em>BioMed
Research International</em> 2020 (January): 1–13. <a href="https://doi.org/10.1155/2020/4071508">https://doi.org/10.1155/2020/4071508</a>.
</div>
<div id="ref-saini-2015" class="csl-entry">
Saini, Harsh, Gaurav Raicar, Alok Sharma, Sunil K. Lal, Abdollah
Dehzangi, James Lyons, Kuldip K. Paliwal, Seiya Imoto, and Satoru
Miyano. 2015. <span>“<span class="nocase">Probabilistic expression of
spatially varied amino acid dimers into general form of Chou’s pseudo
amino acid composition for protein fold recognition</span>.”</span>
<em>Journal of Theoretical Biology</em> 380 (September): 291–98. <a href="https://doi.org/10.1016/j.jtbi.2015.05.030">https://doi.org/10.1016/j.jtbi.2015.05.030</a>.
</div>
<div id="ref-song-2018" class="csl-entry">
Song, Xiaoyu, Zhan-Heng Chen, Xiangyang Sun, Zhu-Hong You, Liping Li,
and Yang Zhao. 2018. <span>“<span class="nocase">An Ensemble Classifier
with Random Projection for Predicting Protein–Protein Interactions Using
Sequence and Evolutionary Information</span>.”</span> <em>Applied
Sciences</em> 8 (1): 89. <a href="https://doi.org/10.3390/app8010089">https://doi.org/10.3390/app8010089</a>.
</div>
<div id="ref-zahiri-2013" class="csl-entry">
Zahiri, Javad, Omid Yaghoubi, Morteza Mohammad-Noori, Reza Ebrahimpour,
and Ali Masoudi-Nejad. 2013. <span>“<span class="nocase">PPIevo :
Protein–protein interaction prediction from PSSM based evolutionary
information</span>.”</span> <em>Genomics</em> 102 (4): 237–42. <a href="https://doi.org/10.1016/j.ygeno.2013.05.006">https://doi.org/10.1016/j.ygeno.2013.05.006</a>.
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
